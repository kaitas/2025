---
draft: false 
date: 2025-01-07
categories:
  - NVIDIA
description: 「NVIDIA Cosmos」物理AIのための世界基盤モデルプラットフォーム

image: img/0022_xlarge.jpg
---

## NVIDIA、物理AI開発を加速する世界基盤モデルプラットフォーム「Cosmos」を発表

**- 最新モデル、ビデオトークナイザー、高速データ処理パイプラインを搭載し、ロボットや自動運転車の開発に特化**
**- 開発者コミュニティ向けにオープンモデルの第一弾を提供開始**
**- 1X、Agile Robots、Agility、Figure AI、Foretellix、Uber、Waabi、XPENGなど、世界の物理AIリーダーが早期採用**

**CES（ネバダ州ラスベガス）- 2025年1月6日** - NVIDIAは本日、最先端の生成的[世界基盤モデル](https://www.nvidia.com/en-us/glossary/world-models/)、高度なトークナイザー、ガードレール、高速ビデオ処理パイプラインから構成されるプラットフォーム、[NVIDIA Cosmos™](http://www.nvidia.com/en-us/ai/cosmos) を発表しました。これは、[自動運転車 (AV)](https://www.nvidia.com/en-us/use-cases/autonomous-vehicle-simulation/) や [ロボット](https://www.nvidia.com/en-us/solutions/robotics-and-edge-computing/) などの [物理AI](https://www.nvidia.com/en-us/glossary/physical-ai/) システムの開発を推進するために構築されたものです。

物理AIモデルの開発にはコストがかかり、膨大な量の実世界データとテストが必要です。Cosmosの世界基盤モデル（WFM）は、開発者が既存のモデルをトレーニングおよび評価するための、フォトリアルで物理ベースの [合成データ](https://www.nvidia.com/en-us/use-cases/synthetic-data/) を大量に生成する簡単な方法を提供します。開発者は、Cosmos WFMをファインチューニングしてカスタムモデルを構築することもできます。

[Cosmosモデル](https://developer.nvidia.com/blog/advancing-physical-ai-with-nvidia-cosmos-world-foundation-model-platform/) は、オープンモデルライセンスの下で提供され、ロボティクスおよびAVコミュニティの作業を加速します。開発者は、[NVIDIA APIカタログ](https://build.nvidia.com/explore/simulation) で最初のモデルをプレビューするか、[NVIDIA NGC™カタログ](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/cosmos/collections/cosmos) または [Hugging Face](https://huggingface.co/collections/nvidia/cosmos-6751e884dc10e013a0a0d8e6) からモデルファミリーとファインチューニングフレームワークをダウンロードできます。

1X、Agile Robots、Agility、Figure AI、Foretellix、Fourier、[Galbot](https://medium.com/@xk.li/galbot-leverages-nvidia-cosmos-to-accelerate-humanoid-development-35be9f8a54d9)、[Hillbot](https://hillbot.ai/blog/hillbot-nvidia-cosmos)、[IntBot](http://intbot.ai/blog/intbot-nvidia-cosmos-service-robotics)、[Neura Robotics](https://neura-robotics.com/nvidia-cosmos-neura-robotics-ai-cognitive-robots-platform)、Skild AI、Virtual Incision、Waabi、XPENGなどの主要なロボティクスおよび自動車企業、そして配車サービス大手のUberが、Cosmosをいち早く採用しています。

「ロボティクスのChatGPTの瞬間が近づいています。大規模言語モデルと同様に、世界基盤モデルはロボットとAVの開発を進める上で不可欠ですが、すべての開発者が独自のモデルをトレーニングするための専門知識とリソースを持っているわけではありません」と、NVIDIAの創業者/CEOであるジェンスン・フアンは述べています。「私たちは、物理AIを民主化し、すべての開発者が汎用ロボティクスを利用できるようにするためにCosmosを開発しました。」

**次世代AIを加速するオープンワールド基盤モデル**
NVIDIA Cosmosのオープンモデルスイートにより、開発者は、ターゲットアプリケーションのニーズに応じて、AVの走行記録や倉庫内を移動するロボットのビデオなどのデータセットでWFMを [カスタマイズ](https://www.nvidia.com/en-us/ai-data-science/products/nemo/) できます。

Cosmos WFMは、物理AIの研究開発専用に構築されており、テキスト、画像、ビデオ、ロボットセンサー、動作データなどの入力の組み合わせから、物理ベースのビデオを生成できます。これらのモデルは、物理ベースの相互作用、オブジェクトの永続性、倉庫や工場などのシミュレートされた産業環境、およびさまざまな道路状況を含む運転環境の高品質な生成のために構築されています。

NVIDIAの創業者/CEOであるジェンスン・フアンは、[CESの基調講演](https://www.nvidia.com/en-us/events/ces/) で、物理AI開発者がCosmosモデルをどのように活用できるかを紹介しました。

*   **ビデオの検索と理解:** 開発者は、雪道や倉庫の混雑など、特定のトレーニングシナリオをビデオデータから簡単に検索できます。
*   **物理ベースのフォトリアルな合成データの生成:** Cosmosモデルを使用して、[NVIDIA Omniverse™](https://nvidianews.nvidia.com/news/nvidia-expands-omniverse-with-generative-physical-ai) プラットフォームで開発された制御された3Dシナリオからフォトリアルなビデオを生成します。
*   **物理AIモデルの開発と評価:** 基盤モデル上にカスタムモデルを構築したり、強化学習のためにCosmosを使用してモデルを改善したり、特定のシミュレートされたシナリオでモデルがどのように動作するかをテストしたりできます。
*   **先見性** **と「マルチバース」シミュレーション:** CosmosとOmniverseを使用して、AIモデルが取り得るすべての将来の結果を生成し、最も正確な最適なパスを選択できるように支援します。

**高度な世界モデル開発ツール**
物理AIモデルの構築には、ペタバイトのビデオデータと、そのデータの処理、キュレーション、ラベル付けに数万時間のコンピューティング時間が必要です。データキュレーション、トレーニング、モデルのカスタマイズにかかる膨大なコストを削減するために、Cosmosは以下を提供します。

*   [NVIDIA NeMo™ Curator](https://developer.nvidia.com/nemo-curator) を活用した **NVIDIA AIおよびCUDA®アクセラレーテッドデータ処理パイプライン**。これにより、開発者はCPUのみのパイプラインで3年以上かかる2,000万時間のビデオを、NVIDIA Blackwellプラットフォームを使用して14日間で処理、キュレーション、ラベル付けできます。
*   [NVIDIA Cosmos Tokenizer](https://developer.nvidia.com/blog/state-of-the-art-multimodal-generative-ai-model-development-with-nvidia-nemo) は、画像とビデオをトークンに変換するための最先端のビジュアルトークナイザーです。現在の主要なトークナイザーと比較して、合計で8倍の圧縮率と12倍の高速処理を実現します。
*   高効率なモデルのトレーニング、カスタマイズ、最適化のための [NVIDIA NeMo](https://www.nvidia.com/en-us/ai-data-science/products/nemo/) フレームワーク。

**世界最大の物理AI産業がCosmosを採用**
物理AI業界の先駆者たちは、すでにCosmosテクノロジーを採用しています。

AIとヒューマノイドロボット企業である1Xは、Cosmos Tokenizerを使用して [1X World Model Challenge](https://www.1x.tech/discover/1x-world-model-sampling-challenge) データセットを立ち上げました。XPENGは、Cosmosを使用してヒューマノイドロボットの開発を加速します。また、HillbotとSkild AIは、Cosmosを使用して汎用ロボットの開発を迅速化しています。

「データの不足と変動性は、ロボット環境での学習を成功させるための重要な課題です」と、Agilityの最高技術責任者であるPras Velagapudi氏は述べています。「Cosmosのテキスト、画像、ビデオから世界への変換機能により、高価な実世界データの取得をそれほど必要とせずに、さまざまなタスクのモデルをトレーニングするために使用できるフォトリアルなシナリオを生成および拡張できます。」

輸送業界のリーダーも、AV用の物理AIを構築するためにCosmosを使用しています。

*   自律走行車を皮切りに物理世界向けの生成的AIを開拓しているWaabiは、AVソフトウェア開発とシミュレーションのためのデータキュレーションの観点からCosmosを評価しています。
*   自動運転用のAI基盤モデルを開発しているWayveは、安全性と検証に使用されるエッジケースとコーナーケースの運転シナリオを検索するためのツールとしてCosmosを評価しています。
*   AVツールチェーンプロバイダーのForetellixは、Cosmosを [NVIDIA Omniverse Sensor RTX API](https://blogs.nvidia.com/blog/omniverse-sensor-rtx-autonomous-machines) と共に使用して、高忠実度のテストシナリオとトレーニングデータを大規模に評価および生成します。
*   世界的な配車サービス大手のUberは、自律走行の推進を加速するためにNVIDIAと提携しています。Uberからの豊富な運転データと、Cosmosプラットフォームおよび [NVIDIA DGX Cloud™](https://www.nvidia.com/en-us/data-center/dgx-cloud) の機能を組み合わせることで、AVパートナーはより強力なAIモデルをさらに効率的に構築できます。

「生成的AIはモビリティの未来を支え、豊富なデータと非常に強力なコンピューティングの両方を必要とします」と、UberのCEOであるDara Khosrowshahi氏は述べています。「NVIDIAと協力することで、業界向けの安全でスケーラブルな自動運転ソリューションのタイムラインを大幅に短縮できると確信しています。」

**オープンで安全かつ責任あるAIの開発**
NVIDIA Cosmosは、[NVIDIAの信頼できるAI](https://www.nvidia.com/en-us/ai-data-science/trustworthy-ai/) の原則に従って [開発されており](https://blogs.nvidia.com/blog/cosmos-world-foundation-models/)、プライバシー、安全性、セキュリティ、透明性を優先し、不要なバイアスを削減します。

信頼できるAIは、開発者コミュニティ内でのイノベーションを促進し、ユーザーの信頼を維持するために不可欠です。NVIDIAは、ホワイトハウスの自主的なAIコミットメントやその他のグローバルなAI安全イニシアチブに沿って、安全で信頼できるAIに取り組んでいます。

オープンなCosmosプラットフォームには、有害なテキストや画像を軽減するように設計されたガードレールが含まれており、精度を高めるためにテキストプロンプトを強化するツールを備えています。NVIDIA APIカタログでCosmosの [オートリグレッシブ](https://build.nvidia.com/nvidia/cosmos-1_0-autoregressive-5b) および [ディフュージョン](https://build.nvidia.com/nvidia/cosmos-1_0-diffusion-7b) モデルで生成されたビデオには、AIが生成したコンテンツを識別するための目に見えない透かしが含まれており、誤報や誤った帰属の可能性を減らすのに役立ちます。

NVIDIAは、開発者が信頼できるAIプラクティスを採用し、アプリケーションのガードレールと透かしソリューションをさらに強化することを推奨しています。

**入手方法**

Cosmos WFMは、Hugging FaceおよびNVIDIA NGCカタログで、NVIDIAのオープンモデルライセンスの下で [現在利用可能](https://developer.nvidia.com/cosmos) です。Cosmosモデルは、完全に最適化された [NVIDIA NIM](https://www.nvidia.com/en-us/ai/) マイクロサービスとして近日中に利用可能になる予定です。

開発者は、高速ビデオ処理のために [NVIDIA NeMo Curator](https://developer.nvidia.com/nemo-curator) にアクセスし、[NVIDIA NeMo](https://www.nvidia.com/en-us/ai-data-science/products/nemo/) で独自の世界モデルをカスタマイズできます。[NVIDIA DGX Cloud](https://www.nvidia.com/en-us/data-center/dgx-cloud/) は、これらのモデルを迅速かつ簡単にデプロイする方法を提供し、[NVIDIA AI Enterprise](https://www.nvidia.com/en-us/data-center/products/ai-enterprise/) ソフトウェアプラットフォームを通じてエンタープライズサポートを利用できます。

NVIDIAはまた、ヘルスケア、金融サービス、製造などのエンタープライズAIユースケースに使用できる新しい [NVIDIA Llama Nemotron大規模言語モデルおよびNVIDIA Cosmos Nemotron視覚言語モデル](https://blogs.nvidia.com/blog/nemotron-model-families) を発表しました。

---

**NVIDIAについて**

[NVIDIA](https://www.nvidia.com/) （NASDAQ: NVDA）は、アクセラレーテッド コンピューティングの世界的なリーダーです。

---
本プレスリリース中の特定の記述は将来の見通しに関する記述であり、リスクと不確実性を含むため、実際の結果は予想と大きく異なる可能性があります。具体的なリスク要因については、NVIDIAが証券取引委員会（SEC）に提出した最新の報告書（Form 10-Kの年次報告書およびForm 10-Qの四半期報告書を含む）を参照してください。SECに提出された報告書のコピーは、同社のウェブサイトに掲載されており、NVIDIAから無料で入手できます。これらの将来の見通しに関する記述は、将来の業績を保証するものではなく、本プレスリリースの日付時点のものであり、法律で義務付けられている場合を除き、NVIDIAは将来の出来事や状況を反映するためにこれらの将来の見通しに関する記述を更新する義務を負いません。

ここに記載されている製品や機能の多くは、さまざまな段階にあり、提供されるかどうかは未定です。上記の記述は、コミットメント、約束、または法的義務を意図したものではなく、またそのように解釈されるべきではありません。当社製品に関して記載されている機能の開発、リリース、およびタイミングは変更される可能性があり、NVIDIAの独自の裁量に委ねられます。NVIDIAは、本プレスリリースに記載されている製品、機能、または機能の提供の失敗または遅延について責任を負いません。

© 2025 NVIDIA Corporation. All rights reserved. NVIDIA、NVIDIAロゴ、CUDA、DGX、NGC、NVIDIA Cosmos、NVIDIA NeMo、およびNVIDIA Omniverseは、米国およびその他の国におけるNVIDIA Corporationの商標および/または登録商標です。その他の会社名および製品名は、それらが関連付けられている各社の商標である可能性があります。機能、価格、可用性、および仕様は予告なく変更されることがあります。


# NVIDIA Cosmos: 物理AIのための世界基盤モデルプラットフォーム

この文章は、NVIDIAが開発した「Cosmos」という、物理AI開発者向けの「世界基盤モデルプラットフォーム」に関するGitHubリポジトリのREADMEを解説したものです。

### Cosmosとは？

[NVIDIA Cosmos](https://www.nvidia.com/cosmos/) は、**物理AI** 開発者が、**物理AIシステム**をより良く、より速く構築できるように設計された、**開発者向けの世界基盤モデルプラットフォーム**です。以下の要素で構成されています。

1. **事前学習済みモデル**: [Hugging Face](https://huggingface.co/collections/nvidia/cosmos-6751e884dc10e013a0a0d8e6) から、[NVIDIA Open Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license/) の下で提供されています。このライセンスにより、**モデルを無料で商用利用できます**。
2. **学習/ファインチューニングスクリプト**: [Apache 2 License](https://www.apache.org/licenses/LICENSE-2.0) の下で、[NVIDIA Nemo Framework](https://github.com/NVIDIA/NeMo) を通じて提供されています。様々な物理AIアプリケーションのためにモデルを学習/ファインチューニングできます。

プラットフォームの詳細は、[Cosmos論文](https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai) で説明されています。プレビューアクセスは [build.nvidia.com](https://build.nvidia.com) で利用可能です。

### 主な特徴

*   **事前学習済み拡散ベース世界基盤モデル**: [Text2WorldおよびVideo2World生成](cosmos1/models/diffusion/README.md) 用。ユーザーはテキストプロンプトやビデオプロンプトに基づいてビジュアルシミュレーションを生成できます。
*   **事前学習済み自己回帰ベース世界基盤モデル**: [Video2World生成](cosmos1/models/autoregressive/README.md) 用。ユーザーはビデオプロンプトとオプションのテキストプロンプトに基づいてビジュアルシミュレーションを生成できます。
*   **ビデオトークナイザー**: [ビデオを効率的かつ効果的に連続トークン（潜在ベクトル）と離散トークン（整数）にトークン化](https://github.com/NVIDIA/Cosmos-Tokenizer) します。
*   **ポストトレーニングスクリプト**: [事前学習済み世界基盤モデルを様々な物理AI設定用にポストトレーニング](cosmos1/models/post_training/README.md) します。
*   **ビデオキュレーションパイプライン**: 独自のビデオデータセットを構築するためのパイプライン。（近日公開予定）
*   **トレーニングスクリプト**: 独自の世界基盤モデルを構築するためのスクリプト。[[拡散モデル](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/diffusion)] [[自己回帰モデル](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/multimodal_autoregressive)]

### モデルファミリー

| モデル名 | 説明 | 試用 |
|---|---|---|
| [Cosmos-1.0-Diffusion-7B-Text2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Text2World) | テキストからビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-14B-Text2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Text2World) | テキストからビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-7B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-14B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Autoregressive-4B](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-4B) | 将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-12B](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-12B) | 将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-5B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-5B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-13B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-13B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Guardrail](https://huggingface.co/nvidia/Cosmos-1.0-Guardrail) | 安全な使用のための事前ガードレールと事後ガードレールを含む | モデル推論スクリプトに組み込み |

### 使用例

#### 推論

Dockerのセットアップについては、[Cosmosインストールガイド](INSTALL.md) を参照してください。事前学習済みモデルを使用した推論については、[Cosmos拡散モデル推論](cosmos1/models/diffusion/README.md) と [Cosmos自己回帰モデル推論](cosmos1/models/autoregressive/README.md) を参照してください。

以下のコードスニペットは、推論の使用方法の概要を示しています。

```bash
PROMPT="A sleek, humanoid robot stands in a vast warehouse filled with neatly stacked cardboard boxes on industrial shelves. \
The robot's metallic body gleams under the bright, even lighting, highlighting its futuristic design and intricate joints. \
A glowing blue light emanates from its chest, adding a touch of advanced technology. The background is dominated by rows of boxes, \
suggesting a highly organized storage system. The floor is lined with wooden pallets, enhancing the industrial setting. \
The camera remains static, capturing the robot's poised stance amidst the orderly environment, with a shallow depth of \
field that keeps the focus on the robot while subtly blurring the background for a cinematic effect."

# 7Bモデルを使用した例
PYTHONPATH=$(pwd) python cosmos1/models/diffusion/inference/text2world.py \
    --checkpoint_dir checkpoints \
    --diffusion_transformer_dir Cosmos-1.0-Diffusion-7B-Text2World \
    --prompt "$PROMPT" \
    --offload_prompt_upsampler \
    --video_save_name Cosmos-1.0-Diffusion-7B-Text2World
```

実行結果の動画はこちらです。

<video src="https://github.com/user-attachments/assets/d3ce56ad-ed6c-445b-a67a-62487e9c32ce">
  Your browser does not support the video tag.
</video>

#### ファインチューニング

詳細については、[Cosmosポストトレーニング](cosmos1/models/post_training/README.md) を参照してください。

### ライセンスと連絡先

このプロジェクトは、追加のサードパーティ製オープンソースソフトウェアプロジェクトをダウンロードしてインストールします。使用前に、これらのオープンソースプロジェクトのライセンス条項を確認してください。

NVIDIA Cosmosのソースコードは、[Apache 2 License](https://www.apache.org/licenses/LICENSE-2.0) の下でリリースされています。

NVIDIA Cosmosのモデルは、[NVIDIA Open Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license) の下でリリースされています。カスタムライセンスについては、[cosmos-license@nvidia.com](mailto:cosmos-license@nvidia.com) までお問い合わせください。

### いったんのまとめ

NVIDIA Cosmosは、物理世界を理解し、シミュレートするAIモデル（物理AI）の開発を支援する強力なプラットフォームです。事前学習済みモデル、学習/ファインチューニングスクリプト、ビデオトークナイザーなど、物理AI開発に必要なツールが揃っています。特に、**商用利用可能な事前学習済みモデルが提供されている**点は、開発者にとって大きなメリットと言えるでしょう。

## Cosmos インストールガイド 日本語訳

この文章では、NVIDIA Cosmosをインストールする手順を説明します。動作確認は、Ubuntu 24.04, 22.04, 20.04でのみ行われていますので、ご注意ください。

**手順:**

1. **NVIDIA Container Toolkitのインストール:**

    まず、[NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) をインストールします。これは、Dockerコンテナ内でGPUを利用するために必要なツールキットです。
    公式ドキュメントに従ってインストールを行ってください。

2. **リポジトリのクローン:**

    次に、Cosmosのリポジトリをクローンします。以下のコマンドを実行します。

    ```bash
    git clone git@github.com:NVIDIA/Cosmos.git
    cd Cosmos
    ```

    このコマンドは、`Cosmos`という名前のディレクトリを作成し、その中にリポジトリのコンテンツをダウンロードします。その後、`cd Cosmos`で`Cosmos`ディレクトリに移動します。

3. **Dockerイメージのビルドとコンテナの実行:**

    最後に、`Dockerfile`を使ってDockerイメージをビルドし、Dockerコンテナを実行します。以下のコマンドを実行します。

    ```bash
    docker build -t cosmos .
    docker run -d --name cosmos_container --gpus all --ipc=host -it -v $(pwd):/workspace cosmos
    docker attach cosmos_container
    ```

    各コマンドの解説:

    *   `docker build -t cosmos .`: 現在のディレクトリにある`Dockerfile`を元に、`cosmos`という名前のDockerイメージをビルドします。
    *   `docker run -d --name cosmos_container --gpus all --ipc=host -it -v $(pwd):/workspace cosmos`: ビルドした`cosmos`イメージから、`cosmos_container`という名前のDockerコンテナをバックグラウンドで実行します。
        *   `-d`: コンテナをバックグラウンドで実行します。
        *   `--name cosmos_container`: コンテナに`cosmos_container`という名前を付けます。
        *   `--gpus all`: コンテナ内ですべてのGPUを利用できるようにします。
        *   `--ipc=host`: ホストとコンテナ間でプロセス間通信(IPC)を共有します。
        *   `-it`: コンテナ内でインタラクティブな操作を可能にします（疑似TTYを割り当て、標準入力をオープンします）。
        *   `-v $(pwd):/workspace`: ホストの現在のディレクトリ(`$(pwd)`)をコンテナ内の`/workspace`ディレクトリにマウントします。これにより、ホストとコンテナ間でファイルを共有できます。
    *   `docker attach cosmos_container`: 実行中の`cosmos_container`コンテナにアタッチします。これにより、コンテナ内でコマンドを実行できるようになります。

**注意点:**

*   この手順は、**Ubuntu 24.04, 22.04, 20.04** でのみ動作確認されています。他のOSでは動作しない可能性があります。
*   **GPUを使用するため、NVIDIAドライバとCUDAがインストールされている必要があります。**
*   Dockerの基本的な知識が必要です。

このガイドを参考に、NVIDIA Cosmosのインストールを完了し、物理AI開発を始めましょう！

