---
draft: false 
date: 2025-01-07
categories:
  - Tech
  - NVIDIA
description: NVIDIA Cosmos: 物理AIのための世界基盤モデルプラットフォーム

image: img/0022_xlarge.jpg
---


# NVIDIA Cosmos: 物理AIのための世界基盤モデルプラットフォーム

この文章は、NVIDIAが開発した「Cosmos」という、物理AI開発者向けの「世界基盤モデルプラットフォーム」に関するGitHubリポジトリのREADMEを解説したものです。

### Cosmosとは？

[NVIDIA Cosmos](https://www.nvidia.com/cosmos/) は、**物理AI** 開発者が、**物理AIシステム**をより良く、より速く構築できるように設計された、**開発者向けの世界基盤モデルプラットフォーム**です。以下の要素で構成されています。

1. **事前学習済みモデル**: [Hugging Face](https://huggingface.co/collections/nvidia/cosmos-6751e884dc10e013a0a0d8e6) から、[NVIDIA Open Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license/) の下で提供されています。このライセンスにより、**モデルを無料で商用利用できます**。
2. **学習/ファインチューニングスクリプト**: [Apache 2 License](https://www.apache.org/licenses/LICENSE-2.0) の下で、[NVIDIA Nemo Framework](https://github.com/NVIDIA/NeMo) を通じて提供されています。様々な物理AIアプリケーションのためにモデルを学習/ファインチューニングできます。

プラットフォームの詳細は、[Cosmos論文](https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai) で説明されています。プレビューアクセスは [build.nvidia.com](https://build.nvidia.com) で利用可能です。

### 主な特徴

*   **事前学習済み拡散ベース世界基盤モデル**: [Text2WorldおよびVideo2World生成](cosmos1/models/diffusion/README.md) 用。ユーザーはテキストプロンプトやビデオプロンプトに基づいてビジュアルシミュレーションを生成できます。
*   **事前学習済み自己回帰ベース世界基盤モデル**: [Video2World生成](cosmos1/models/autoregressive/README.md) 用。ユーザーはビデオプロンプトとオプションのテキストプロンプトに基づいてビジュアルシミュレーションを生成できます。
*   **ビデオトークナイザー**: [ビデオを効率的かつ効果的に連続トークン（潜在ベクトル）と離散トークン（整数）にトークン化](https://github.com/NVIDIA/Cosmos-Tokenizer) します。
*   **ポストトレーニングスクリプト**: [事前学習済み世界基盤モデルを様々な物理AI設定用にポストトレーニング](cosmos1/models/post_training/README.md) します。
*   **ビデオキュレーションパイプライン**: 独自のビデオデータセットを構築するためのパイプライン。（近日公開予定）
*   **トレーニングスクリプト**: 独自の世界基盤モデルを構築するためのスクリプト。[[拡散モデル](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/diffusion)] [[自己回帰モデル](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/multimodal_autoregressive)]

### モデルファミリー

| モデル名 | 説明 | 試用 |
|---|---|---|
| [Cosmos-1.0-Diffusion-7B-Text2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Text2World) | テキストからビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-14B-Text2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Text2World) | テキストからビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-7B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-7B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Diffusion-14B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Diffusion-14B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/diffusion/README.md) |
| [Cosmos-1.0-Autoregressive-4B](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-4B) | 将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-12B](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-12B) | 将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-5B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-5B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Autoregressive-13B-Video2World](https://huggingface.co/nvidia/Cosmos-1.0-Autoregressive-13B-Video2World) | ビデオ + テキストに基づく将来のビジュアルワールド生成 | [推論](cosmos1/models/autoregressive/README.md) |
| [Cosmos-1.0-Guardrail](https://huggingface.co/nvidia/Cosmos-1.0-Guardrail) | 安全な使用のための事前ガードレールと事後ガードレールを含む | モデル推論スクリプトに組み込み |

### 使用例

#### 推論

Dockerのセットアップについては、[Cosmosインストールガイド](INSTALL.md) を参照してください。事前学習済みモデルを使用した推論については、[Cosmos拡散モデル推論](cosmos1/models/diffusion/README.md) と [Cosmos自己回帰モデル推論](cosmos1/models/autoregressive/README.md) を参照してください。

以下のコードスニペットは、推論の使用方法の概要を示しています。

```bash
PROMPT="A sleek, humanoid robot stands in a vast warehouse filled with neatly stacked cardboard boxes on industrial shelves. \
The robot's metallic body gleams under the bright, even lighting, highlighting its futuristic design and intricate joints. \
A glowing blue light emanates from its chest, adding a touch of advanced technology. The background is dominated by rows of boxes, \
suggesting a highly organized storage system. The floor is lined with wooden pallets, enhancing the industrial setting. \
The camera remains static, capturing the robot's poised stance amidst the orderly environment, with a shallow depth of \
field that keeps the focus on the robot while subtly blurring the background for a cinematic effect."

# 7Bモデルを使用した例
PYTHONPATH=$(pwd) python cosmos1/models/diffusion/inference/text2world.py \
    --checkpoint_dir checkpoints \
    --diffusion_transformer_dir Cosmos-1.0-Diffusion-7B-Text2World \
    --prompt "$PROMPT" \
    --offload_prompt_upsampler \
    --video_save_name Cosmos-1.0-Diffusion-7B-Text2World
```

実行結果の動画はこちらです。

<video src="https://github.com/user-attachments/assets/d3ce56ad-ed6c-445b-a67a-62487e9c32ce">
  Your browser does not support the video tag.
</video>

#### ファインチューニング

詳細については、[Cosmosポストトレーニング](cosmos1/models/post_training/README.md) を参照してください。

### ライセンスと連絡先

このプロジェクトは、追加のサードパーティ製オープンソースソフトウェアプロジェクトをダウンロードしてインストールします。使用前に、これらのオープンソースプロジェクトのライセンス条項を確認してください。

NVIDIA Cosmosのソースコードは、[Apache 2 License](https://www.apache.org/licenses/LICENSE-2.0) の下でリリースされています。

NVIDIA Cosmosのモデルは、[NVIDIA Open Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-open-model-license) の下でリリースされています。カスタムライセンスについては、[cosmos-license@nvidia.com](mailto:cosmos-license@nvidia.com) までお問い合わせください。

### いったんのまとめ

NVIDIA Cosmosは、物理世界を理解し、シミュレートするAIモデル（物理AI）の開発を支援する強力なプラットフォームです。事前学習済みモデル、学習/ファインチューニングスクリプト、ビデオトークナイザーなど、物理AI開発に必要なツールが揃っています。特に、**商用利用可能な事前学習済みモデルが提供されている**点は、開発者にとって大きなメリットと言えるでしょう。

## Cosmos インストールガイド 日本語訳

この文章では、NVIDIA Cosmosをインストールする手順を説明します。動作確認は、Ubuntu 24.04, 22.04, 20.04でのみ行われていますので、ご注意ください。

**手順:**

1. **NVIDIA Container Toolkitのインストール:**

    まず、[NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) をインストールします。これは、Dockerコンテナ内でGPUを利用するために必要なツールキットです。
    公式ドキュメントに従ってインストールを行ってください。

2. **リポジトリのクローン:**

    次に、Cosmosのリポジトリをクローンします。以下のコマンドを実行します。

    ```bash
    git clone git@github.com:NVIDIA/Cosmos.git
    cd Cosmos
    ```

    このコマンドは、`Cosmos`という名前のディレクトリを作成し、その中にリポジトリのコンテンツをダウンロードします。その後、`cd Cosmos`で`Cosmos`ディレクトリに移動します。

3. **Dockerイメージのビルドとコンテナの実行:**

    最後に、`Dockerfile`を使ってDockerイメージをビルドし、Dockerコンテナを実行します。以下のコマンドを実行します。

    ```bash
    docker build -t cosmos .
    docker run -d --name cosmos_container --gpus all --ipc=host -it -v $(pwd):/workspace cosmos
    docker attach cosmos_container
    ```

    各コマンドの解説:

    *   `docker build -t cosmos .`: 現在のディレクトリにある`Dockerfile`を元に、`cosmos`という名前のDockerイメージをビルドします。
    *   `docker run -d --name cosmos_container --gpus all --ipc=host -it -v $(pwd):/workspace cosmos`: ビルドした`cosmos`イメージから、`cosmos_container`という名前のDockerコンテナをバックグラウンドで実行します。
        *   `-d`: コンテナをバックグラウンドで実行します。
        *   `--name cosmos_container`: コンテナに`cosmos_container`という名前を付けます。
        *   `--gpus all`: コンテナ内ですべてのGPUを利用できるようにします。
        *   `--ipc=host`: ホストとコンテナ間でプロセス間通信(IPC)を共有します。
        *   `-it`: コンテナ内でインタラクティブな操作を可能にします（疑似TTYを割り当て、標準入力をオープンします）。
        *   `-v $(pwd):/workspace`: ホストの現在のディレクトリ(`$(pwd)`)をコンテナ内の`/workspace`ディレクトリにマウントします。これにより、ホストとコンテナ間でファイルを共有できます。
    *   `docker attach cosmos_container`: 実行中の`cosmos_container`コンテナにアタッチします。これにより、コンテナ内でコマンドを実行できるようになります。

**注意点:**

*   この手順は、**Ubuntu 24.04, 22.04, 20.04** でのみ動作確認されています。他のOSでは動作しない可能性があります。
*   **GPUを使用するため、NVIDIAドライバとCUDAがインストールされている必要があります。**
*   Dockerの基本的な知識が必要です。

このガイドを参考に、NVIDIA Cosmosのインストールを完了し、物理AI開発を始めましょう！

